{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "from train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = '2007_trainval.txt'\n",
    "log_dir = 'logs/000/'\n",
    "weights_path='model_data/yolo_weights.h5'\n",
    "classes_path = 'model_data/voc_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "val_split = 0.1\n",
    "\n",
    "\n",
    "input_shape = (608, 608) # multiple of 32, hw\n",
    "\n",
    "is_tiny_version = len(anchors)==6 # default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 21) vs (255, 1024, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((21,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 21) vs (255, 512, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((21,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 21) vs (255, 256, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "/anaconda3/envs/py36-test/lib/python3.6/site-packages/keras/engine/topology.py:3462: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((21,) vs (255,)).\n",
      "  weight_values[i].shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n"
     ]
    }
   ],
   "source": [
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "model = create_model(input_shape, anchors, num_classes,\n",
    "                     freeze_body=2, weights_path=weights_path) # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, val on 7 samples, with batch size 32.\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 513s 257s/step - loss: 18066.5576 - val_loss: 15950.8135\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 445s 222s/step - loss: 14072.2241 - val_loss: 13027.6123\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 519s 259s/step - loss: 11045.7539 - val_loss: 9936.9570\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 451s 226s/step - loss: 8624.7292 - val_loss: 8144.3804\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 2292s 1146s/step - loss: 6861.9880 - val_loss: 6431.7705\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 595s 298s/step - loss: 5331.5237 - val_loss: 4845.4258\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 940s 470s/step - loss: 4259.4784 - val_loss: 3784.4165\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 509s 255s/step - loss: 3639.3052 - val_loss: 3137.2805\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 467s 234s/step - loss: 2815.9014 - val_loss: 2539.8257\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 453s 227s/step - loss: 2362.5557 - val_loss: 2030.0310\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 509s 254s/step - loss: 2104.8442 - val_loss: 1904.7640\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 519s 260s/step - loss: 1644.7034 - val_loss: 1519.0841\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 513s 257s/step - loss: 1444.6800 - val_loss: 1265.3304\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 521s 260s/step - loss: 1316.2687 - val_loss: 1219.7318\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 524s 262s/step - loss: 1194.7079 - val_loss: 1018.9180\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 465s 232s/step - loss: 1054.7579 - val_loss: 948.9609\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 462s 231s/step - loss: 934.4473 - val_loss: 831.8294\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 460s 230s/step - loss: 870.0253 - val_loss: 754.0327\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 447s 223s/step - loss: 816.1114 - val_loss: 707.5139\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 2673s 1337s/step - loss: 739.9191 - val_loss: 629.0854\n",
      "Epoch 21/50\n",
      "1/2 [==============>...............] - ETA: 3:12 - loss: 720.8171"
     ]
    }
   ],
   "source": [
    "# Train with frozen layers first, to get a stable loss.\n",
    "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "    # use custom yolo_loss Lambda layer.\n",
    "    'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "batch_size = 32\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=50,\n",
    "        initial_epoch=0,\n",
    "        callbacks=[logging, checkpoint])\n",
    "model.save_weights(log_dir + 'trained_weights_stage_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze and continue training, to fine-tune.\n",
    "# Train longer if the result is not good.\n",
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable = True\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "print('Unfreeze all of the layers.')\n",
    "\n",
    "batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "    steps_per_epoch=max(1, num_train//batch_size),\n",
    "    validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "    validation_steps=max(1, num_val//batch_size),\n",
    "    epochs=100,\n",
    "    initial_epoch=50,\n",
    "    callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "# Further training if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
